import cv2
import mediapipe as mp

mp_hands = mp.solutions.hands

# Initialize video capture
cap = cv2.VideoCapture(0)

# Initialize MediaPipe Hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.2)

# Define mapping from hand landmarks to sign language words or phrases
landmark_to_word = {
    mp_hands.HandLandmark.WRIST: " ",
    mp_hands.HandLandmark.THUMB_TIP: "A",
    mp_hands.HandLandmark.THUMB_IP: "B",
    mp_hands.HandLandmark.THUMB_MCP: "C",
    mp_hands.HandLandmark.INDEX_FINGER_TIP: "D",
    mp_hands.HandLandmark.INDEX_FINGER_DIP: "E",
    mp_hands.HandLandmark.INDEX_FINGER_PIP: "F",
    mp_hands.HandLandmark.INDEX_FINGER_MCP: "G",
    mp_hands.HandLandmark.MIDDLE_FINGER_TIP: "H",
    mp_hands.HandLandmark.MIDDLE_FINGER_DIP: "I",
    mp_hands.HandLandmark.MIDDLE_FINGER_PIP: "J",
    mp_hands.HandLandmark.MIDDLE_FINGER_MCP: "K",
    mp_hands.HandLandmark.RING_FINGER_TIP: "L",
    mp_hands.HandLandmark.RING_FINGER_DIP: "M",
    mp_hands.HandLandmark.RING_FINGER_PIP: "N",
    mp_hands.HandLandmark.RING_FINGER_MCP: "O",
    mp_hands.HandLandmark.PINKY_TIP: "P",
    mp_hands.HandLandmark.PINKY_DIP: "Q",
    mp_hands.HandLandmark.PINKY_PIP: "R",
    mp_hands.HandLandmark.PINKY_MCP: "S",
    mp_hands.HandLandmark.THUMB_CMC: "T",
    mp_hands.HandLandmark.INDEX_FINGER_MCP: "U",
    mp_hands.HandLandmark.MIDDLE_FINGER_MCP: "V",
    mp_hands.HandLandmark.RING_FINGER_MCP: "W",
    mp_hands.HandLandmark.PINKY_MCP: "X",
    mp_hands.HandLandmark.INDEX_FINGER_TIP: "Y",
    mp_hands.HandLandmark.MIDDLE_FINGER_TIP: "Z",
    mp_hands.HandLandmark.THUMB_CMC: "Thumb CMC",
    mp_hands.HandLandmark.INDEX_FINGER_MCP: "Index MCP",
    mp_hands.HandLandmark.MIDDLE_FINGER_MCP: "Middle MCP",
}

while cap.isOpened():
    success, image = cap.read()
    if not success:
        break

    # Convert the BGR image to RGB
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Process the image with MediaPipe Hands
    results = hands.process(image)

    # Get hand landmarks
    hand_gesture = ""
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:          
            # Process hand landmarks to map to sign language words or phrases
            for lm in mp_hands.HandLandmark:
                # Map the landmark to a word or phrase
                if lm in landmark_to_word and hand_landmarks.landmark[lm].visibility > 0.2:
                    hand_gesture += landmark_to_word[lm]
           
            # Display the resulting image with hand landmarks
            mp_drawing = mp.solutions.drawing_utils
            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Print the translated gesture if it's not empty
    if hand_gesture:
        print(hand_gesture)
        cv2.putText(image, hand_gesture, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    # Display the resulting image
    cv2.imshow('MediaPipe Hands', image)

    # Exit on ESC key press
    if cv2.waitKey(5) & 0xFF == 27:
        break

# Release video capture
cap.release()

# Close all windows
cv2.destroyAllWindows()
